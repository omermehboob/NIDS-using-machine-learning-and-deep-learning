{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN (NIDS_BINARY).ipynb",
      "provenance": [],
      "mount_file_id": "12JDBEo_aDXtC78AYVnmcNoq-8HOECcAB",
      "authorship_tag": "ABX9TyMzAa4mkycI3/vKgevqRwod",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omermehboob/NIDS-using-machine-learning-and-deep-learning/blob/main/DNN_1.2(NIDS_BINARY).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XGTjj5KpJhqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
      ],
      "metadata": {
        "id": "x6nBeqvIJcxf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Refined_data_set(label_encoding_18_features).csv')"
      ],
      "metadata": {
        "id": "ToyjNtbpJgwu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJnDNjuqKXs4",
        "outputId": "f525ef5e-c022-4456-d71e-34b965906136"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1336498, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "fRYQYqC0KXmp",
        "outputId": "d4217498-efc8-4cde-ed25-810e158b6270"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Bwd Packet Length Max  Bwd Packet Length Mean  \\\n",
              "0           0                  128.0              128.000000   \n",
              "1           1                    0.0                0.000000   \n",
              "2           2                    0.0                0.000000   \n",
              "3           3                   48.0               48.000000   \n",
              "4           4                 1486.0              186.136364   \n",
              "\n",
              "   Bwd Packet Length Std  Flow Bytes/s  Flow Duration  Flow IAT Max  \\\n",
              "0                0.00000          2046         193460      164110.0   \n",
              "1                0.00000             7        4016867     4011885.0   \n",
              "2                0.00000             2        5318063     5302748.0   \n",
              "3                0.00000       1081081            148          99.0   \n",
              "4              426.14309            57      117320451    10100000.0   \n",
              "\n",
              "   Flow IAT Mean  Flow IAT Min  Flow IAT Std  Fwd IAT Total  \\\n",
              "0   3.869200e+04           3.0  7.124800e+04        29304.0   \n",
              "1   1.004217e+06          10.0  2.005113e+06      4016867.0   \n",
              "2   1.772688e+06          97.0  3.057131e+06      5318063.0   \n",
              "3   4.933333e+01           1.0  4.901360e+01           48.0   \n",
              "4   2.550445e+06          39.0  4.191832e+06    117000000.0   \n",
              "\n",
              "   Fwd Packet Length Max  Fwd Packet Length Mean  Fwd Packet Length Min  \\\n",
              "0                   35.0                   35.00                   35.0   \n",
              "1                    6.0                    6.00                    6.0   \n",
              "2                    6.0                    4.00                    0.0   \n",
              "3                   32.0                   32.00                   32.0   \n",
              "4                  453.0                  107.64                    0.0   \n",
              "\n",
              "   Fwd Packet Length Std  Total Backward Packets  Total Fwd Packets  \\\n",
              "0               0.000000                       2                  4   \n",
              "1               0.000000                       0                  5   \n",
              "2               3.464102                       1                  3   \n",
              "3               0.000000                       2                  2   \n",
              "4             181.667939                      22                 25   \n",
              "\n",
              "   Total Length of Bwd Packets  Total Length of Fwd Packets  Label  \n",
              "0                        256.0                        140.0      1  \n",
              "1                          0.0                         30.0      0  \n",
              "2                          0.0                         12.0      1  \n",
              "3                         96.0                         64.0      1  \n",
              "4                       4095.0                       2691.0      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcfca426-f450-41ab-9396-6b9907790e34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2046</td>\n",
              "      <td>193460</td>\n",
              "      <td>164110.0</td>\n",
              "      <td>3.869200e+04</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.124800e+04</td>\n",
              "      <td>29304.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.00</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>256.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>7</td>\n",
              "      <td>4016867</td>\n",
              "      <td>4011885.0</td>\n",
              "      <td>1.004217e+06</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.005113e+06</td>\n",
              "      <td>4016867.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2</td>\n",
              "      <td>5318063</td>\n",
              "      <td>5302748.0</td>\n",
              "      <td>1.772688e+06</td>\n",
              "      <td>97.0</td>\n",
              "      <td>3.057131e+06</td>\n",
              "      <td>5318063.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>48.0</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1081081</td>\n",
              "      <td>148</td>\n",
              "      <td>99.0</td>\n",
              "      <td>4.933333e+01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.901360e+01</td>\n",
              "      <td>48.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.00</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>96.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1486.0</td>\n",
              "      <td>186.136364</td>\n",
              "      <td>426.14309</td>\n",
              "      <td>57</td>\n",
              "      <td>117320451</td>\n",
              "      <td>10100000.0</td>\n",
              "      <td>2.550445e+06</td>\n",
              "      <td>39.0</td>\n",
              "      <td>4.191832e+06</td>\n",
              "      <td>117000000.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>107.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181.667939</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>4095.0</td>\n",
              "      <td>2691.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcfca426-f450-41ab-9396-6b9907790e34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcfca426-f450-41ab-9396-6b9907790e34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcfca426-f450-41ab-9396-6b9907790e34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = pd.read_csv('/content/drive/MyDrive/Refined_data_set(label_encoding_18_features).csv')"
      ],
      "metadata": {
        "id": "v3KQo59IKXh3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfTnMtqzMCrE",
        "outputId": "398d753d-4a00-4371-9dfc-cad75a9270dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1336498, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=newdf[[\"Bwd Packet Length Max\",\"Bwd Packet Length Mean\",\"Bwd Packet Length Std\",\"Flow Bytes/s\",\n",
        "\"Flow Duration\",\"Flow IAT Max\",\"Flow IAT Mean\",\"Flow IAT Min\",\"Flow IAT Std\",\"Fwd IAT Total\",\"Fwd Packet Length Max\",\n",
        "\"Fwd Packet Length Mean\",\"Fwd Packet Length Min\",\"Fwd Packet Length Std\",\"Total Backward Packets\",\"Total Fwd Packets\",\n",
        "\"Total Length of Bwd Packets\",\"Total Length of Fwd Packets\"]]\n",
        "y=newdf[[\"Label\"]]"
      ],
      "metadata": {
        "id": "VKPlZCc8MGEN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEb_68m6MCno",
        "outputId": "e3cd12c4-96be-4a91-caf8-9ffa4742dbf2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1336498, 18)\n",
            "(1336498, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
        "\n"
      ],
      "metadata": {
        "id": "YeuthgGBKXbG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Normalizer().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "scaler = Normalizer().fit(y_train)\n",
        "y_train = scaler.transform(y_train)\n"
      ],
      "metadata": {
        "id": "txQEjXSYMlj1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(700,input_dim=18,activation='relu'))  \n",
        "model.add(Dropout(0.10))\n",
        "model.add(Dense(350,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(125,activation='relu'))  \n",
        "model.add(Dropout(0.01))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKSrH6D7Mlef",
        "outputId": "e4575b29-fc14-45b1-81c5-8a26767058ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 700)               13300     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 700)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 350)               245350    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 350)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 125)               43875     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 125)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 126       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 302,651\n",
            "Trainable params: 302,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=512, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkl-SEn_MlUB",
        "outputId": "dae59bda-99df-4fdb-d4ac-59317cf1f823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2089/2089 [==============================] - 13s 4ms/step - loss: 0.3189 - accuracy: 0.8732 - val_loss: 24112148.0000 - val_accuracy: 0.8311\n",
            "Epoch 2/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.2890 - accuracy: 0.8823 - val_loss: 12653440.0000 - val_accuracy: 0.8300\n",
            "Epoch 3/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.2218 - accuracy: 0.9089 - val_loss: 1790894.8750 - val_accuracy: 0.7907\n",
            "Epoch 4/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1858 - accuracy: 0.9267 - val_loss: 1901506.6250 - val_accuracy: 0.6495\n",
            "Epoch 5/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1725 - accuracy: 0.9321 - val_loss: 3638741.0000 - val_accuracy: 0.6433\n",
            "Epoch 6/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1680 - accuracy: 0.9338 - val_loss: 4310082.0000 - val_accuracy: 0.6685\n",
            "Epoch 7/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1634 - accuracy: 0.9350 - val_loss: 4945078.0000 - val_accuracy: 0.8113\n",
            "Epoch 8/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1612 - accuracy: 0.9359 - val_loss: 5974474.0000 - val_accuracy: 0.7827\n",
            "Epoch 9/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1620 - accuracy: 0.9360 - val_loss: 4727182.0000 - val_accuracy: 0.8250\n",
            "Epoch 10/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1594 - accuracy: 0.9375 - val_loss: 3660333.7500 - val_accuracy: 0.8223\n",
            "Epoch 11/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1573 - accuracy: 0.9381 - val_loss: 6667521.0000 - val_accuracy: 0.8180\n",
            "Epoch 12/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1536 - accuracy: 0.9394 - val_loss: 3918713.5000 - val_accuracy: 0.8177\n",
            "Epoch 13/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1499 - accuracy: 0.9408 - val_loss: 6671826.5000 - val_accuracy: 0.8253\n",
            "Epoch 14/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1504 - accuracy: 0.9407 - val_loss: 4831430.0000 - val_accuracy: 0.8012\n",
            "Epoch 15/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1495 - accuracy: 0.9407 - val_loss: 5766293.5000 - val_accuracy: 0.8075\n",
            "Epoch 16/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1454 - accuracy: 0.9422 - val_loss: 5644204.0000 - val_accuracy: 0.8061\n",
            "Epoch 17/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1453 - accuracy: 0.9423 - val_loss: 7803255.0000 - val_accuracy: 0.8057\n",
            "Epoch 18/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1426 - accuracy: 0.9434 - val_loss: 14850639.0000 - val_accuracy: 0.8124\n",
            "Epoch 19/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1408 - accuracy: 0.9438 - val_loss: 13797447.0000 - val_accuracy: 0.8162\n",
            "Epoch 20/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1415 - accuracy: 0.9435 - val_loss: 13453284.0000 - val_accuracy: 0.8099\n",
            "Epoch 21/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1366 - accuracy: 0.9454 - val_loss: 4621468.5000 - val_accuracy: 0.7988\n",
            "Epoch 22/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1342 - accuracy: 0.9462 - val_loss: 12453113.0000 - val_accuracy: 0.8201\n",
            "Epoch 23/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1394 - accuracy: 0.9439 - val_loss: 21408372.0000 - val_accuracy: 0.8247\n",
            "Epoch 24/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1378 - accuracy: 0.9443 - val_loss: 20173510.0000 - val_accuracy: 0.8243\n",
            "Epoch 25/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1351 - accuracy: 0.9452 - val_loss: 24400176.0000 - val_accuracy: 0.8208\n",
            "Epoch 26/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1315 - accuracy: 0.9469 - val_loss: 21565662.0000 - val_accuracy: 0.8248\n",
            "Epoch 27/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1347 - accuracy: 0.9455 - val_loss: 12263957.0000 - val_accuracy: 0.8196\n",
            "Epoch 28/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1328 - accuracy: 0.9464 - val_loss: 26144606.0000 - val_accuracy: 0.8229\n",
            "Epoch 29/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9471 - val_loss: 31870796.0000 - val_accuracy: 0.8262\n",
            "Epoch 30/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1298 - accuracy: 0.9478 - val_loss: 28848924.0000 - val_accuracy: 0.8201\n",
            "Epoch 31/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1315 - accuracy: 0.9469 - val_loss: 42202752.0000 - val_accuracy: 0.8259\n",
            "Epoch 32/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1326 - accuracy: 0.9465 - val_loss: 59151124.0000 - val_accuracy: 0.8261\n",
            "Epoch 33/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1315 - accuracy: 0.9466 - val_loss: 65397088.0000 - val_accuracy: 0.8265\n",
            "Epoch 34/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1319 - accuracy: 0.9467 - val_loss: 63811944.0000 - val_accuracy: 0.8264\n",
            "Epoch 35/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1279 - accuracy: 0.9485 - val_loss: 70739568.0000 - val_accuracy: 0.8270\n",
            "Epoch 36/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1303 - accuracy: 0.9474 - val_loss: 66978892.0000 - val_accuracy: 0.8264\n",
            "Epoch 37/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1304 - accuracy: 0.9468 - val_loss: 76192280.0000 - val_accuracy: 0.7971\n",
            "Epoch 38/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1263 - accuracy: 0.9490 - val_loss: 81723256.0000 - val_accuracy: 0.8260\n",
            "Epoch 39/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1334 - accuracy: 0.9454 - val_loss: 52452412.0000 - val_accuracy: 0.7964\n",
            "Epoch 40/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1312 - accuracy: 0.9461 - val_loss: 39481060.0000 - val_accuracy: 0.8286\n",
            "Epoch 41/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1276 - accuracy: 0.9480 - val_loss: 33474178.0000 - val_accuracy: 0.8274\n",
            "Epoch 42/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1274 - accuracy: 0.9476 - val_loss: 24099764.0000 - val_accuracy: 0.8275\n",
            "Epoch 43/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1278 - accuracy: 0.9477 - val_loss: 20643566.0000 - val_accuracy: 0.7946\n",
            "Epoch 44/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1269 - accuracy: 0.9478 - val_loss: 30024592.0000 - val_accuracy: 0.8238\n",
            "Epoch 45/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1241 - accuracy: 0.9493 - val_loss: 30482288.0000 - val_accuracy: 0.7879\n",
            "Epoch 46/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1229 - accuracy: 0.9496 - val_loss: 26825944.0000 - val_accuracy: 0.7991\n",
            "Epoch 47/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1244 - accuracy: 0.9485 - val_loss: 21370486.0000 - val_accuracy: 0.7889\n",
            "Epoch 48/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1230 - accuracy: 0.9494 - val_loss: 31429376.0000 - val_accuracy: 0.8268\n",
            "Epoch 49/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1221 - accuracy: 0.9497 - val_loss: 30889724.0000 - val_accuracy: 0.8269\n",
            "Epoch 50/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1224 - accuracy: 0.9494 - val_loss: 30158432.0000 - val_accuracy: 0.8286\n",
            "Epoch 51/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1230 - accuracy: 0.9497 - val_loss: 50687720.0000 - val_accuracy: 0.8271\n",
            "Epoch 52/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1171 - accuracy: 0.9525 - val_loss: 61191080.0000 - val_accuracy: 0.8271\n",
            "Epoch 53/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1181 - accuracy: 0.9523 - val_loss: 48622228.0000 - val_accuracy: 0.8142\n",
            "Epoch 54/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1164 - accuracy: 0.9528 - val_loss: 29836596.0000 - val_accuracy: 0.7985\n",
            "Epoch 55/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1165 - accuracy: 0.9530 - val_loss: 33280786.0000 - val_accuracy: 0.8263\n",
            "Epoch 56/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1159 - accuracy: 0.9531 - val_loss: 42366808.0000 - val_accuracy: 0.8287\n",
            "Epoch 57/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1147 - accuracy: 0.9537 - val_loss: 40582152.0000 - val_accuracy: 0.8269\n",
            "Epoch 58/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1153 - accuracy: 0.9535 - val_loss: 42673916.0000 - val_accuracy: 0.8280\n",
            "Epoch 59/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1158 - accuracy: 0.9536 - val_loss: 60450948.0000 - val_accuracy: 0.8296\n",
            "Epoch 60/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1161 - accuracy: 0.9530 - val_loss: 55954120.0000 - val_accuracy: 0.8298\n",
            "Epoch 61/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1136 - accuracy: 0.9543 - val_loss: 49281652.0000 - val_accuracy: 0.8302\n",
            "Epoch 62/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1113 - accuracy: 0.9553 - val_loss: 26274572.0000 - val_accuracy: 0.8276\n",
            "Epoch 63/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1119 - accuracy: 0.9550 - val_loss: 28049560.0000 - val_accuracy: 0.8247\n",
            "Epoch 64/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1134 - accuracy: 0.9541 - val_loss: 33497112.0000 - val_accuracy: 0.8278\n",
            "Epoch 65/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1113 - accuracy: 0.9553 - val_loss: 44031944.0000 - val_accuracy: 0.8301\n",
            "Epoch 66/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1108 - accuracy: 0.9554 - val_loss: 64111020.0000 - val_accuracy: 0.8301\n",
            "Epoch 67/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1128 - accuracy: 0.9544 - val_loss: 66123852.0000 - val_accuracy: 0.8309\n",
            "Epoch 68/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1106 - accuracy: 0.9553 - val_loss: 98696176.0000 - val_accuracy: 0.8305\n",
            "Epoch 69/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1097 - accuracy: 0.9558 - val_loss: 174482352.0000 - val_accuracy: 0.8306\n",
            "Epoch 70/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1129 - accuracy: 0.9542 - val_loss: 163109968.0000 - val_accuracy: 0.8305\n",
            "Epoch 71/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1108 - accuracy: 0.9552 - val_loss: 181439248.0000 - val_accuracy: 0.8305\n",
            "Epoch 72/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1113 - accuracy: 0.9551 - val_loss: 122388384.0000 - val_accuracy: 0.8305\n",
            "Epoch 73/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1081 - accuracy: 0.9565 - val_loss: 190189600.0000 - val_accuracy: 0.8288\n",
            "Epoch 74/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1091 - accuracy: 0.9563 - val_loss: 195465792.0000 - val_accuracy: 0.8297\n",
            "Epoch 75/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1101 - accuracy: 0.9557 - val_loss: 226866288.0000 - val_accuracy: 0.8306\n",
            "Epoch 76/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1096 - accuracy: 0.9558 - val_loss: 238735104.0000 - val_accuracy: 0.8304\n",
            "Epoch 77/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1111 - accuracy: 0.9551 - val_loss: 213060432.0000 - val_accuracy: 0.8305\n",
            "Epoch 78/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1081 - accuracy: 0.9565 - val_loss: 241071072.0000 - val_accuracy: 0.8304\n",
            "Epoch 79/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1101 - accuracy: 0.9557 - val_loss: 299289504.0000 - val_accuracy: 0.8302\n",
            "Epoch 80/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1082 - accuracy: 0.9566 - val_loss: 297348448.0000 - val_accuracy: 0.8304\n",
            "Epoch 81/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1074 - accuracy: 0.9567 - val_loss: 447053344.0000 - val_accuracy: 0.8303\n",
            "Epoch 82/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1090 - accuracy: 0.9558 - val_loss: 559294528.0000 - val_accuracy: 0.8305\n",
            "Epoch 83/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1086 - accuracy: 0.9561 - val_loss: 545766848.0000 - val_accuracy: 0.8305\n",
            "Epoch 84/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1063 - accuracy: 0.9570 - val_loss: 532636992.0000 - val_accuracy: 0.8304\n",
            "Epoch 85/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1077 - accuracy: 0.9564 - val_loss: 660422784.0000 - val_accuracy: 0.8305\n",
            "Epoch 86/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1060 - accuracy: 0.9572 - val_loss: 757629376.0000 - val_accuracy: 0.8305\n",
            "Epoch 87/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1068 - accuracy: 0.9568 - val_loss: 851681024.0000 - val_accuracy: 0.8303\n",
            "Epoch 88/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1049 - accuracy: 0.9576 - val_loss: 647072768.0000 - val_accuracy: 0.8305\n",
            "Epoch 89/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1065 - accuracy: 0.9568 - val_loss: 781070976.0000 - val_accuracy: 0.8297\n",
            "Epoch 90/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1079 - accuracy: 0.9563 - val_loss: 835101696.0000 - val_accuracy: 0.8295\n",
            "Epoch 91/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1047 - accuracy: 0.9575 - val_loss: 810779200.0000 - val_accuracy: 0.8303\n",
            "Epoch 92/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1054 - accuracy: 0.9571 - val_loss: 661939200.0000 - val_accuracy: 0.8304\n",
            "Epoch 93/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1066 - accuracy: 0.9569 - val_loss: 659690944.0000 - val_accuracy: 0.8305\n",
            "Epoch 94/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1026 - accuracy: 0.9584 - val_loss: 715237952.0000 - val_accuracy: 0.8304\n",
            "Epoch 95/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1050 - accuracy: 0.9578 - val_loss: 843532096.0000 - val_accuracy: 0.8304\n",
            "Epoch 96/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1057 - accuracy: 0.9574 - val_loss: 856592768.0000 - val_accuracy: 0.8304\n",
            "Epoch 97/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1047 - accuracy: 0.9579 - val_loss: 882300352.0000 - val_accuracy: 0.8304\n",
            "Epoch 98/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1073 - accuracy: 0.9569 - val_loss: 835494080.0000 - val_accuracy: 0.8303\n",
            "Epoch 99/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1059 - accuracy: 0.9574 - val_loss: 1006090880.0000 - val_accuracy: 0.8298\n",
            "Epoch 100/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1047 - accuracy: 0.9578 - val_loss: 974808320.0000 - val_accuracy: 0.8305\n",
            "Epoch 101/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1053 - accuracy: 0.9577 - val_loss: 1057751552.0000 - val_accuracy: 0.8302\n",
            "Epoch 102/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1046 - accuracy: 0.9577 - val_loss: 1086492416.0000 - val_accuracy: 0.8303\n",
            "Epoch 103/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1044 - accuracy: 0.9577 - val_loss: 898665024.0000 - val_accuracy: 0.8296\n",
            "Epoch 104/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1044 - accuracy: 0.9577 - val_loss: 978475136.0000 - val_accuracy: 0.8304\n",
            "Epoch 105/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1021 - accuracy: 0.9587 - val_loss: 868492736.0000 - val_accuracy: 0.8304\n",
            "Epoch 106/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1025 - accuracy: 0.9584 - val_loss: 951531584.0000 - val_accuracy: 0.8278\n",
            "Epoch 107/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1026 - accuracy: 0.9584 - val_loss: 1198000896.0000 - val_accuracy: 0.8304\n",
            "Epoch 108/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1026 - accuracy: 0.9583 - val_loss: 1559230720.0000 - val_accuracy: 0.8303\n",
            "Epoch 109/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1028 - accuracy: 0.9584 - val_loss: 1496638464.0000 - val_accuracy: 0.8304\n",
            "Epoch 110/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1062 - accuracy: 0.9573 - val_loss: 1542358656.0000 - val_accuracy: 0.8295\n",
            "Epoch 111/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1076 - accuracy: 0.9559 - val_loss: 1478823936.0000 - val_accuracy: 0.8302\n",
            "Epoch 112/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1037 - accuracy: 0.9581 - val_loss: 1748248320.0000 - val_accuracy: 0.8295\n",
            "Epoch 113/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1033 - accuracy: 0.9579 - val_loss: 1763185664.0000 - val_accuracy: 0.8295\n",
            "Epoch 114/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1035 - accuracy: 0.9579 - val_loss: 1659773440.0000 - val_accuracy: 0.8302\n",
            "Epoch 115/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1017 - accuracy: 0.9587 - val_loss: 2165806080.0000 - val_accuracy: 0.8295\n",
            "Epoch 116/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1058 - accuracy: 0.9567 - val_loss: 1809157888.0000 - val_accuracy: 0.8305\n",
            "Epoch 117/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1037 - accuracy: 0.9575 - val_loss: 2043849472.0000 - val_accuracy: 0.8296\n",
            "Epoch 118/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1016 - accuracy: 0.9586 - val_loss: 1954978688.0000 - val_accuracy: 0.8295\n",
            "Epoch 119/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1026 - accuracy: 0.9582 - val_loss: 2382116352.0000 - val_accuracy: 0.8295\n",
            "Epoch 120/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1021 - accuracy: 0.9585 - val_loss: 2102938112.0000 - val_accuracy: 0.8303\n",
            "Epoch 121/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1022 - accuracy: 0.9584 - val_loss: 2271710464.0000 - val_accuracy: 0.8279\n",
            "Epoch 122/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1015 - accuracy: 0.9589 - val_loss: 2164165120.0000 - val_accuracy: 0.8296\n",
            "Epoch 123/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1027 - accuracy: 0.9581 - val_loss: 2399037184.0000 - val_accuracy: 0.8279\n",
            "Epoch 124/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1010 - accuracy: 0.9588 - val_loss: 2631253504.0000 - val_accuracy: 0.8278\n",
            "Epoch 125/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1019 - accuracy: 0.9586 - val_loss: 2687841536.0000 - val_accuracy: 0.8279\n",
            "Epoch 126/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1010 - accuracy: 0.9592 - val_loss: 2696150784.0000 - val_accuracy: 0.8279\n",
            "Epoch 127/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1020 - accuracy: 0.9586 - val_loss: 3153398784.0000 - val_accuracy: 0.8266\n",
            "Epoch 128/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0997 - accuracy: 0.9596 - val_loss: 3752674560.0000 - val_accuracy: 0.8278\n",
            "Epoch 129/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1014 - accuracy: 0.9588 - val_loss: 3584058112.0000 - val_accuracy: 0.8278\n",
            "Epoch 130/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1016 - accuracy: 0.9591 - val_loss: 3653312256.0000 - val_accuracy: 0.8279\n",
            "Epoch 131/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0991 - accuracy: 0.9599 - val_loss: 3859914752.0000 - val_accuracy: 0.8278\n",
            "Epoch 132/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1000 - accuracy: 0.9595 - val_loss: 4012187648.0000 - val_accuracy: 0.8278\n",
            "Epoch 133/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1010 - accuracy: 0.9589 - val_loss: 3452943616.0000 - val_accuracy: 0.8279\n",
            "Epoch 134/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1001 - accuracy: 0.9593 - val_loss: 4296540672.0000 - val_accuracy: 0.8266\n",
            "Epoch 135/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0984 - accuracy: 0.9599 - val_loss: 3929741056.0000 - val_accuracy: 0.8267\n",
            "Epoch 136/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0992 - accuracy: 0.9597 - val_loss: 4600801792.0000 - val_accuracy: 0.8266\n",
            "Epoch 137/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1014 - accuracy: 0.9586 - val_loss: 4084575744.0000 - val_accuracy: 0.8267\n",
            "Epoch 138/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1026 - accuracy: 0.9580 - val_loss: 4338542592.0000 - val_accuracy: 0.8278\n",
            "Epoch 139/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1013 - accuracy: 0.9587 - val_loss: 4064179712.0000 - val_accuracy: 0.8278\n",
            "Epoch 140/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1017 - accuracy: 0.9586 - val_loss: 4758898688.0000 - val_accuracy: 0.8278\n",
            "Epoch 141/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1009 - accuracy: 0.9588 - val_loss: 4950477824.0000 - val_accuracy: 0.8267\n",
            "Epoch 142/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1007 - accuracy: 0.9589 - val_loss: 4543324672.0000 - val_accuracy: 0.8267\n",
            "Epoch 143/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0984 - accuracy: 0.9598 - val_loss: 5065672704.0000 - val_accuracy: 0.8267\n",
            "Epoch 144/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1003 - accuracy: 0.9590 - val_loss: 4889874944.0000 - val_accuracy: 0.8267\n",
            "Epoch 145/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1001 - accuracy: 0.9594 - val_loss: 4347645952.0000 - val_accuracy: 0.8278\n",
            "Epoch 146/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1002 - accuracy: 0.9596 - val_loss: 5077040640.0000 - val_accuracy: 0.8278\n",
            "Epoch 147/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0998 - accuracy: 0.9595 - val_loss: 4219036160.0000 - val_accuracy: 0.8278\n",
            "Epoch 148/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1000 - accuracy: 0.9593 - val_loss: 4518953984.0000 - val_accuracy: 0.8267\n",
            "Epoch 149/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1019 - accuracy: 0.9583 - val_loss: 4789087232.0000 - val_accuracy: 0.8267\n",
            "Epoch 150/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0992 - accuracy: 0.9597 - val_loss: 4789865472.0000 - val_accuracy: 0.8267\n",
            "Epoch 151/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0981 - accuracy: 0.9601 - val_loss: 5803327488.0000 - val_accuracy: 0.8267\n",
            "Epoch 152/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0987 - accuracy: 0.9599 - val_loss: 5528943104.0000 - val_accuracy: 0.8267\n",
            "Epoch 153/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0984 - accuracy: 0.9599 - val_loss: 5936130560.0000 - val_accuracy: 0.8244\n",
            "Epoch 154/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1015 - accuracy: 0.9583 - val_loss: 5605739008.0000 - val_accuracy: 0.8266\n",
            "Epoch 155/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0997 - accuracy: 0.9594 - val_loss: 5683372544.0000 - val_accuracy: 0.8266\n",
            "Epoch 156/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.1002 - accuracy: 0.9592 - val_loss: 5907219456.0000 - val_accuracy: 0.8266\n",
            "Epoch 157/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0986 - accuracy: 0.9596 - val_loss: 6076781056.0000 - val_accuracy: 0.8266\n",
            "Epoch 158/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0973 - accuracy: 0.9603 - val_loss: 6249538560.0000 - val_accuracy: 0.8266\n",
            "Epoch 159/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0993 - accuracy: 0.9596 - val_loss: 5985925632.0000 - val_accuracy: 0.8266\n",
            "Epoch 160/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0981 - accuracy: 0.9599 - val_loss: 7311932416.0000 - val_accuracy: 0.8266\n",
            "Epoch 161/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0978 - accuracy: 0.9602 - val_loss: 7903330304.0000 - val_accuracy: 0.8277\n",
            "Epoch 162/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0973 - accuracy: 0.9604 - val_loss: 7509854208.0000 - val_accuracy: 0.8277\n",
            "Epoch 163/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0982 - accuracy: 0.9598 - val_loss: 7847554560.0000 - val_accuracy: 0.8266\n",
            "Epoch 164/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0989 - accuracy: 0.9597 - val_loss: 8471520768.0000 - val_accuracy: 0.8266\n",
            "Epoch 165/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0969 - accuracy: 0.9605 - val_loss: 8494870528.0000 - val_accuracy: 0.8278\n",
            "Epoch 166/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0973 - accuracy: 0.9603 - val_loss: 8891620352.0000 - val_accuracy: 0.8266\n",
            "Epoch 167/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0971 - accuracy: 0.9604 - val_loss: 8448990208.0000 - val_accuracy: 0.8266\n",
            "Epoch 168/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0973 - accuracy: 0.9603 - val_loss: 8580497920.0000 - val_accuracy: 0.8277\n",
            "Epoch 169/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0965 - accuracy: 0.9606 - val_loss: 9323202560.0000 - val_accuracy: 0.8266\n",
            "Epoch 170/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0985 - accuracy: 0.9601 - val_loss: 8974919680.0000 - val_accuracy: 0.8265\n",
            "Epoch 171/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0985 - accuracy: 0.9599 - val_loss: 8860751872.0000 - val_accuracy: 0.8266\n",
            "Epoch 172/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0962 - accuracy: 0.9608 - val_loss: 9613171712.0000 - val_accuracy: 0.8265\n",
            "Epoch 173/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.1004 - accuracy: 0.9589 - val_loss: 10570887168.0000 - val_accuracy: 0.8265\n",
            "Epoch 174/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0977 - accuracy: 0.9600 - val_loss: 10970671104.0000 - val_accuracy: 0.8266\n",
            "Epoch 175/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0963 - accuracy: 0.9605 - val_loss: 10839940096.0000 - val_accuracy: 0.8265\n",
            "Epoch 176/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0976 - accuracy: 0.9599 - val_loss: 12291608576.0000 - val_accuracy: 0.8265\n",
            "Epoch 177/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0965 - accuracy: 0.9603 - val_loss: 12877136896.0000 - val_accuracy: 0.8265\n",
            "Epoch 178/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0971 - accuracy: 0.9604 - val_loss: 11969335296.0000 - val_accuracy: 0.8266\n",
            "Epoch 179/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0956 - accuracy: 0.9606 - val_loss: 12264429568.0000 - val_accuracy: 0.8266\n",
            "Epoch 180/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0968 - accuracy: 0.9603 - val_loss: 13228506112.0000 - val_accuracy: 0.8266\n",
            "Epoch 181/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0970 - accuracy: 0.9602 - val_loss: 12359334912.0000 - val_accuracy: 0.8266\n",
            "Epoch 182/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0973 - accuracy: 0.9601 - val_loss: 11824428032.0000 - val_accuracy: 0.8265\n",
            "Epoch 183/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0943 - accuracy: 0.9614 - val_loss: 12273261568.0000 - val_accuracy: 0.8265\n",
            "Epoch 184/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0967 - accuracy: 0.9604 - val_loss: 14093842432.0000 - val_accuracy: 0.8243\n",
            "Epoch 185/200\n",
            "2089/2089 [==============================] - 9s 4ms/step - loss: 0.0958 - accuracy: 0.9606 - val_loss: 12240088064.0000 - val_accuracy: 0.8266\n",
            "Epoch 186/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0960 - accuracy: 0.9607 - val_loss: 13609899008.0000 - val_accuracy: 0.8265\n",
            "Epoch 187/200\n",
            "2089/2089 [==============================] - 8s 4ms/step - loss: 0.0949 - accuracy: 0.9611 - val_loss: 14868570112.0000 - val_accuracy: 0.8266\n",
            "Epoch 188/200\n",
            "1636/2089 [======================>.......] - ETA: 1s - loss: 0.0956 - accuracy: 0.9610"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tahLSx0JH16"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}